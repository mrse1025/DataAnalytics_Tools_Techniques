{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Scraping Project\n",
    "## Victoria Espinola\n",
    "### BNQ164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import urllib.parse, urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFreqList(arg1):\n",
    "    # write your code here\n",
    "    setp = set(arg1)\n",
    "    freq_dict= dict().fromkeys(setp,0)\n",
    "    for x in arg1: \n",
    "        freq_dict[x] += 1\n",
    "    return freq_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index  frequency\n",
      "0       maximum          1\n",
      "1          2006          1\n",
      "2    increasing          2\n",
      "3       respect          1\n",
      "4     particles          2\n",
      "..          ...        ...\n",
      "168    directly          1\n",
      "169       graph          6\n",
      "170      region          6\n",
      "171      14,778          1\n",
      "172    indicate          2\n",
      "\n",
      "[173 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file1= open(\"teacher5_unknown.pdf\", \"rb\")\n",
    "pdfReader = PyPDF2.PdfFileReader(file1)\n",
    "cleanedWords= list()\n",
    "word_dict=dict()\n",
    "count = 0\n",
    "big1, big2, big3 = 0,0,0\n",
    "for page in range(pdfReader.numPages):\n",
    "    pageObj = pdfReader.getPage(page)\n",
    "    text = (pageObj.extractText())\n",
    "    #print(text)\n",
    "    words= nltk.word_tokenize(text.strip().lower())\n",
    "    for word in words:\n",
    "        stoplist= stopwords.words('english')\n",
    "        length = len(word)\n",
    "        if length !=1 and word not in stoplist:\n",
    "            cleanedWords.append(word)\n",
    "    \n",
    "word_dict= calcFreqList(cleanedWords)\n",
    "df=pd.DataFrame.from_dict(word_dict, orient='index',columns=['frequency']).reset_index().rename(columns={df.columns[0]:'word'})\n",
    "print(df)\n",
    "#if re.search('[Ll]im*', line):\n",
    "         #   big1 =+1\n",
    "        #elif re.search (\"[Dd]eriv*\",line):\n",
    "        #    big2 = +1\n",
    "        #elif re.search(\"[iI]ntegr*\",line):\n",
    "        #    big3 = +1\n",
    "    #print(big1, big2, big3)\n",
    "file1.close()\n",
    "    \n",
    "#print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index  frequency\n",
      "145      find         10\n",
      "30       time          9\n",
      "79   particle          9\n",
      "41     volume          8\n",
      "159   gallons          6\n",
      "..        ...        ...\n",
      "58    leaking          1\n",
      "57        1.4          1\n",
      "55      hours          1\n",
      "54    surface          1\n",
      "86    defined          1\n",
      "\n",
      "[173 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sort= df.sort_values(by=['frequency'], ascending = False)\n",
    "print(df_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
